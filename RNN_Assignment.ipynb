{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_char_rnn (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvgBiZaAS-S"
      },
      "source": [
        "# Homework: classify the origin of names using a character-level RNN\n",
        "\n",
        "In this homework we will use an rnn-based model to perform classification. The goal is threefold:\n",
        "\n",
        "1. Get more hands on with the preprocessing needed to perform text classification from A to Z. No preprocessing is done for you!\n",
        "2. Use embeddings and RNNs in conjunction at the character level to perform classification.\n",
        "3. Write a function that takes as input a string, and outputs the name of the predicted class.\n",
        "\n",
        "However, here are guidelines to help you through all the steps:\n",
        "\n",
        "1. Figure out the number of classes, and map the classes to integers (or one-hot vectors). This is needed for fitting the model and training it to do classification.\n",
        "2. Use the keras tokenizer at the character level to tokenize your input into integer sequences.\n",
        "3. Pad your sequences using the keras preprocessing tools.\n",
        "4. Build a model that uses, minimally, an embedding layer, an RNN (of your choice) and a dense layer to output the logits or probabilities for the target classes (name origins).\n",
        "5. Fit the model and evaluate on the test set.\n",
        "6. Write a function that takes a string as input and predicts the origin (as its original string value)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxpRYUBTCANr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85e11150-dc23-4f62-82b7-67a3cdd4e588"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF1BqaO7-A2g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "9b8b0703-a693-4d32-9fa4-26ab401de1b8"
      },
      "source": [
        "# Download the data\n",
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-26 02:24:10--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 54.192.151.68, 54.192.151.109, 54.192.151.98, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|54.192.151.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-03-26 02:24:10 (86.9 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnj5MDEJ-u-q"
      },
      "source": [
        "\n",
        "data = []\n",
        "for filename in glob('data/names/*.txt'):\n",
        "  origin = filename.split('/')[-1].split('.txt')[0]\n",
        "  names = open(filename).readlines()\n",
        "  for name in names:\n",
        "    data.append((name.strip(), origin))\n",
        "\n",
        "names, origins = zip(*data)\n",
        "names_train, names_test, origins_train, origins_test = train_test_split(names, origins, test_size=0.25, shuffle=True, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUhDpvskAHZ1"
      },
      "source": [
        "# Lets look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ux9M4DV-A5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "60fde431-515b-4b9e-8112-162adbee8cab"
      },
      "source": [
        "for name, origin in zip(names_train[:20], origins_train[:20]):\n",
        "  print(name.ljust(20), origin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adashik              Russian\n",
            "Farina               Italian\n",
            "Pirumov              Russian\n",
            "Ridge                English\n",
            "Babyuk               Russian\n",
            "Monet                French\n",
            "Ukhabin              Russian\n",
            "Agaltsov             Russian\n",
            "Marfelev             Russian\n",
            "Evelson              Russian\n",
            "Gulko                Russian\n",
            "Finyagin             Russian\n",
            "Rogatko              Russian\n",
            "Albani               Italian\n",
            "Colombo              Italian\n",
            "Katoaka              Japanese\n",
            "Nowak                Czech\n",
            "Nahas                Arabic\n",
            "Koury                Arabic\n",
            "Pakholkov            Russian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xESBh1qu6kUo"
      },
      "source": [
        "def predict_origin(name):\n",
        "  assert isinstance(name, str)\n",
        "  # do something with the model\n",
        "  # do something with model output\n",
        "  the_origin = None\n",
        "  return the_origin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ23CDNGBNeg"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ1u-U7--hCo"
      },
      "source": [
        "**Task 1:**<br>\n",
        "Figure out the number of classes, and map the classes to integers (or one-hot vectors). This is needed for fitting the model and training it to do classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbriVUIp6vJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b32b810-1b75-4ddd-a697-7d2094852715"
      },
      "source": [
        "len(set(origins)), len(origins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 20074)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKEzmqCJa1yQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a24e84f6-03af-411c-ad54-594be6dc5254"
      },
      "source": [
        "origins_train[:7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Russian', 'Italian', 'Russian', 'English', 'Russian', 'French', 'Russian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPqUlrdOHDBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37cbde2c-2205-4300-b629-eab9ba70cdd0"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(origins_train)\n",
        "y_train = le.transform(origins_train)\n",
        "y_test = le.transform(origins_test)\n",
        "\n",
        "y_train[:10], y_test[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([14,  9, 14,  4, 14,  5, 14, 14, 14, 14]),\n",
              " array([14,  0,  3, 16,  4,  0, 14, 14, 14, 14]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp5g9cdBapau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6814089c-0cae-4b05-a29c-a6e252505e84"
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French',\n",
              "       'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean',\n",
              "       'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish',\n",
              "       'Vietnamese'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIqcU7Aw__98"
      },
      "source": [
        "**Task 2:**<br>\n",
        "Use the keras tokenizer at the character level to tokenize your input into integer sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcrE0GHl-xv3"
      },
      "source": [
        "encoder = tf.keras.preprocessing.text.Tokenizer(num_words=None, \n",
        "                                   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
        "                                   lower=True, \n",
        "                                   split=' ', \n",
        "                                   char_level=True,\n",
        "                                   oov_token=None, \n",
        "                                   document_count=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPvN4CZ-3iP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "835d42ef-7af7-4d2f-d1d4-cf0daceb1d44"
      },
      "source": [
        "encoder.fit_on_texts(names_train)\n",
        "sequences = encoder.texts_to_sequences(names_train)\n",
        "for i in range(5):\n",
        "  print('{} ---> {}'.format(names_train[i], sequences[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adashik ---> [1, 15, 1, 7, 8, 4, 9]\n",
            "Farina ---> [21, 1, 6, 4, 5, 1]\n",
            "Pirumov ---> [22, 4, 6, 13, 14, 2, 11]\n",
            "Ridge ---> [6, 4, 15, 18, 3]\n",
            "Babyuk ---> [16, 1, 16, 17, 13, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JCQsXjoMOVs"
      },
      "source": [
        "sequences_test = encoder.texts_to_sequences(names_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_22aVWVHC7tP"
      },
      "source": [
        "**Task 3:** <br>\n",
        "Pad your sequences using the keras preprocessing tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8xUE2jGBsdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b15a6287-6c09-42f0-8691-56e841a7283e"
      },
      "source": [
        "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "sequences_test = tf.keras.preprocessing.sequence.pad_sequences(sequences_test, padding='post')\n",
        "for i in range(5):\n",
        "  print('{} ---> {}'.format(names_train[i], sequences[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adashik ---> [ 1 15  1  7  8  4  9  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "Farina ---> [21  1  6  4  5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "Pirumov ---> [22  4  6 13 14  2 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "Ridge ---> [ 6  4 15 18  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "Babyuk ---> [16  1 16 17 13  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL0KSJ6tESHD"
      },
      "source": [
        "**Task 4 & 5** :<br>\n",
        "- Build a model that uses, minimally, an embedding layer, an RNN (of your choice) and a dense layer to output the logits or probabilities for the target classes (name origins). <br>\n",
        "- Fit the model and evaluate on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57l_gyA5CZ4Z"
      },
      "source": [
        "embedding_input_dim = max(encoder.index_word) + 1\n",
        "embedding_output_dim = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFhhQxD7DcKY"
      },
      "source": [
        "model = tf.keras.models.Sequential(layers=[\n",
        "                                           tf.keras.layers.Embedding(input_dim=embedding_input_dim,\n",
        "                                                                     output_dim=embedding_output_dim),\n",
        "                                           tf.keras.layers.LSTM(units=64),\n",
        "                                           tf.keras.layers.Dense(23, activation=\"tanh\"),\n",
        "                                           tf.keras.layers.Dense(18, activation= 'softmax')\n",
        "                                           ])\n",
        "\n",
        "model.compile(optimizer= 'adam',  metrics=['accuracy'],\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_q-bnuIDk90"
      },
      "source": [
        "history = model.fit(np.array(sequences),y_train, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcdiqtZzMIfr"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdmTMXe3G0fT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71c8bd39-603d-4656-9f40-15295bd82ad2"
      },
      "source": [
        "model.evaluate(sequences_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5019/5019 [==============================] - 1s 144us/sample - loss: 0.7233 - accuracy: 0.7954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7233220070547068, 0.79537755]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bA_OefENB1m"
      },
      "source": [
        "Accuracy on the test set : **80 %** \n",
        "Not Bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp53XMZjNNfx"
      },
      "source": [
        "**Task 6** :<br>\n",
        "Write a function that takes a string as input and predicts the origin (as its original string value)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8CLpSw3JkHp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "98007d62-17ce-4711-883d-6ad3a034e03f"
      },
      "source": [
        "def predict_origin(name):\n",
        "  assert isinstance(name, str)\n",
        "  \n",
        "  # sequence is Local variable \n",
        "  name = name\n",
        "  sequence = [x[0] for x in encoder.texts_to_sequences(name)]\n",
        "  sequence = sequence + (len(sequences[0]) - len(sequence)+1) * [0]\n",
        "  sequence = np.array([sequence])\n",
        "\n",
        "  # the result of prediction is output of softmax, we pick the label with th highest probability\n",
        "  p = model.predict(sequence)\n",
        "  label = np.argmax(p)\n",
        "  the_origin = le.inverse_transform([label])[0]\n",
        "  return the_origin\n",
        "\n",
        "names_list = ['Micheal', 'YU', 'Julio', 'ahmad','stillitano']\n",
        "for x in names_list:\n",
        "  print('name -->{},   Model_prediction --> {}'.format(x, predict_origin(x)))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name -->Micheal,   Model_prediction --> English\n",
            "name -->YU,   Model_prediction --> Chinese\n",
            "name -->Julio,   Model_prediction --> Russian\n",
            "name -->ahmad,   Model_prediction --> Arabic\n",
            "name -->stillitano,   Model_prediction --> Italian\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}